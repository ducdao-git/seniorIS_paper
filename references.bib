%% This BibTeX bibliography file was created using BibDesk.
%% http://www.cs.ucsd.edu/~mmccrack/bibdesk.html
%% Created for Jon Breitenbucher at 2005-09-15 16:48:40 -0400 
%% Saved with string encoding UTF-8 

@book{szeliski_cv_book,
  title={Computer vision: algorithms and applications},
  author={Szeliski, Richard},
  year={2022},
  publisher={Springer Nature}
}

@article{fscore_2017,
  title={Tanks and temples: Benchmarking large-scale scene reconstruction},
  author={Knapitsch, Arno and Park, Jaesik and Zhou, Qian-Yi and Koltun, Vladlen},
  journal={ACM Transactions on Graphics (ToG)},
  volume={36},
  number={4},
  pages={1--13},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@article{n_point_interpolation_ap,
  title={An enhanced N-point interpolation method to eliminate average precision distortion},
  author={Zhang, Haodi and Rogozan, Alexandrina and Bensrhair, Abdelaziz},
  journal={Pattern Recognition Letters},
  volume={158},
  pages={111--116},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{coco_2014,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@article{pascal_voc_2015,
  title={The pascal visual object classes challenge: A retrospective},
  author={Everingham, Mark and Eslami, SM Ali and Van Gool, Luc and Williams, Christopher KI and Winn, John and Zisserman, Andrew},
  journal={International journal of computer vision},
  volume={111},
  pages={98--136},
  year={2015},
  publisher={Springer}
}

@article{confusion_matrix_2017,
  title={A Bayesian interpretation of the confusion matrix},
  author={Caelen, Olivier},
  journal={Annals of Mathematics and Artificial Intelligence},
  volume={81},
  number={3-4},
  pages={429--450},
  year={2017},
  publisher={Springer}
}

@inproceedings{metrics_survey_2020,
  title={A survey on performance metrics for object-detection algorithms},
  author={Padilla, Rafael and Netto, Sergio L and Da Silva, Eduardo AB},
  booktitle={2020 international conference on systems, signals and image processing (IWSSIP)},
  pages={237--242},
  year={2020},
  organization={IEEE}
}

@inbook{2d_svm_Tzotsos,
  author    = {Tzotsos, A.
               and Argialas, D.},
  editor    = {Blaschke, Thomas
               and Lang, Stefan
               and Hay, Geoffrey J.},
  title     = {Support Vector Machine Classification for Object-Based Image Analysis},
  booktitle = {Object-Based Image Analysis: Spatial Concepts for Knowledge-Driven Remote Sensing Applications},
  year      = {2008},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {663--677},
  abstract  = {The Support Vector Machine is a theoretically superior machine learning methodology with great results in pattern recognition. Especially for supervised classification of high-dimensional datasets and has been found competitive with the best machine learning algorithms. In the past, SVMs were tested and evaluated only as pixel-based image classifiers. During recent years, advances in Remote Sensing occurred in the field of Object-Based Image Analysis (OBIA) with combination of low level and high level computer vision techniques. Moving from pixel-based techniques towards object-based representation, the dimensions of remote sensing imagery feature space increases significantly. This results to increased complexity of the classification process, and causes problems to traditional classification schemes. The objective of this study was to evaluate SVMs for their effectiveness and prospects for object-based image analysis as a modern computational intelligence method. Here, an SVM approach for multi-class classification was followed, based on primitive image objects provided by a multi-resolution segmentation algorithm. Then, a feature selection step took place in order to provide the features for classification which involved spectral, texture and shape information. After the feature selection step, a module that integrated an SVM classifier and the segmentation algorithm was developed in C++. For training the SVM, sample image objects derived from the segmentation procedure were used. The proposed classification procedure followed, resulting in the final object classification. The classification results were compared to the Nearest Neighbor object-based classifier results, and were found satisfactory. The SVM methodology seems very promising for Object Based Image Analysis and future work will focus on integrating SVM classifiers with rule-based classifiers.},
  isbn      = {978-3-540-77058-9},
  doi       = {10.1007/978-3-540-77058-9_36},
  url       = {https://doi.org/10.1007/978-3-540-77058-9_36}
}

@misc{ahsan_2020,
  title     = {Convolutional neural network and regularization techniques with TensorFlow and keras},
  url       = {https://medium.com/intelligentmachines/convolutional-neural-network-and-regularization-techniques-with-tensorflow-and-keras-5a09e6e65dc7},
  journal   = {Medium},
  publisher = {intelligentmachines},
  author    = {Ahsan, Ahmad Omar},
  year      = {2020},
  month     = {Jun}
} 

@article{AlexNet_2017,
  title     = {Imagenet classification with deep convolutional neural networks},
  author    = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal   = {Communications of the ACM},
  volume    = {60},
  number    = {6},
  pages     = {84--90},
  year      = {2017},
  publisher = {AcM New York, NY, USA}
}

@misc{analytics_vidhya_2021,
  title   = {Building resnet-34 model using Pytorch - A Guide for Beginners},
  url     = {https://www.analyticsvidhya.com/blog/2021/09/building-resnet-34-model-using-pytorch-a-guide-for-beginners/},
  author  = {Siddharth M},
  journal = {Analytics Vidhya},
  year    = {2021},
  month   = {Sep}
}

@incollection{bengio2012practical,
  title     = {Practical recommendations for gradient-based training of deep architectures},
  author    = {Bengio, Yoshua},
  booktitle = {Neural networks: Tricks of the trade},
  pages     = {437--478},
  year      = {2012},
  publisher = {Springer}
}

@inproceedings{deconv_rcnn_2018,
  title        = {Deconv R-CNN for small object detection on remote sensing images},
  author       = {Zhang, Wei and Wang, Shihao and Thachan, Sophanyouly and Chen, Jingzhou and Qian, Yuntao},
  booktitle    = {IGARSS 2018-2018 IEEE International Geoscience and Remote Sensing Symposium},
  pages        = {2483--2486},
  year         = {2018},
  organization = {IEEE}
}

@book{diff_detection_segmentation_task_fig,
  title        = {Robotic Manipulation},
  subtitle     = {Perception, Planning, and Control},
  howpublished = {Course Notes for MIT 6.4210},
  author       = {Tedrake, Russ},
  year         = 2022,
  url          = {http://manipulation.mit.edu}
}

@inproceedings{fast_rcnn_og,
  title     = {Fast r-cnn},
  author    = {Girshick, Ross},
  booktitle = {Proceedings of the IEEE international conference on computer vision},
  pages     = {1440--1448},
  year      = {2015}
}


@article{faster_rcnn_2015,
  title   = {Faster r-cnn: Towards real-time object detection with region proposal networks},
  author  = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal = {Advances in neural information processing systems},
  volume  = {28},
  year    = {2015}
}

@article{faster_rcnn_architecture_fig,
  author  = {Deng, Zhipeng and Sun, Hao and Zhou, Shilin and Zhao, Juanping and Lei, Lin and Zou, Huanxin},
  year    = {2018},
  month   = {05},
  pages   = {},
  title   = {Multi-scale object detection in remote sensing imagery with convolutional neural networks},
  volume  = {145},
  journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
  doi     = {10.1016/j.isprsjprs.2018.04.003}
}

@article{fcn_archite_2018,
  author  = {Piramanayagam, Sankaranarayanan and Saber, Eli and Schwartzkopf, Wade and Koehler, Frederick},
  year    = {2018},
  month   = {09},
  pages   = {1429},
  title   = {Supervised Classification of Multisensor Remotely Sensed Images Using a Deep Learning Framework},
  volume  = {10},
  journal = {Remote Sensing},
  doi     = {10.3390/rs10091429}
}

@article{felzenszwalb_huttenlocher_2004,
  title   = {Efficient graph-based image segmentation},
  volume  = {59},
  doi     = {10.1023/b:visi.0000022288.19776.77},
  number  = {2},
  journal = {International Journal of Computer Vision},
  author  = {Felzenszwalb, Pedro F. and Huttenlocher, Daniel P.},
  year    = {2004},
  pages   = {167-181}
}

@inproceedings{generalized_iou,
  title     = {Generalized intersection over union: A metric and a loss for bounding box regression},
  author    = {Rezatofighi, Hamid and Tsoi, Nathan and Gwak, JunYoung and Sadeghian, Amir and Reid, Ian and Savarese, Silvio},
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages     = {658--666},
  year      = {2019}
}

@article{Girshick_R_CNN_2013,
  author     = {Ross B. Girshick and Jeff Donahue and Trevor Darrell and Jitendra Malik},
  title      = {Rich feature hierarchies for accurate object detection and semantic segmentation},
  journal    = {CoRR},
  volume     = {abs/1311.2524},
  year       = {2013},
  url        = {http://arxiv.org/abs/1311.2524},
  eprinttype = {arXiv},
  eprint     = {1311.2524},
  timestamp  = {Mon, 13 Aug 2018 16:48:09 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/GirshickDDM13.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
} 

@article{grigorescu_trasnea_cocias_macesanu_2020,
  title   = {A survey of Deep Learning techniques for autonomous driving},
  author  = {Grigorescu, Sorin and Trasnea, Bogdan and Cocias, Tiberiu and Macesanu, Gigel},
  volume  = {37},
  doi     = {10.1002/rob.21918},
  number  = {3},
  journal = {Journal of Field Robotics},
  year    = {2020},
  pages   = {362-386}
}

@inproceedings{He_2015_ICCV,
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  title     = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  month     = {December},
  year      = {2015}
} 

@inproceedings{huang2017densely,
  title     = {Densely connected convolutional networks},
  author    = {Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {4700--4708},
  year      = {2017}
} 

@incollection{lecun2012efficient,
  title     = {Efficient backprop},
  author    = {LeCun, Yann A and Bottou, Leon and Orr, Genevieve B and Muller, Klaus-Robert},
  booktitle = {Neural networks: Tricks of the trade},
  pages     = {9-48},
  year      = {2012},
  publisher = {Springer},
  annote    = {The paper proposes a Convolutional Neural Network (CNN) model called DenseNet. The idea of this model is that it connects each layer directly to every other layer in the network. This model inspires by the fact that CNN needs shorter paths from the input layer to the output layer. This need is due to the problem of input and gradient information lost as it travels through a deep network. Since all layers are directly connected, this model preserved the state after each layer and the original input information. All information is available until the final classifier, thus making this network data lost proof.}
} 

@article{lecun2015deep,
  title     = {Deep learning},
  author    = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal   = {nature},
  volume    = {521},
  number    = {7553},
  pages     = {436--444},
  year      = {2015},
  publisher = {Nature Publishing Group}
}

@article{li2021survey,
  title     = {A survey of convolutional neural networks: analysis, applications, and prospects},
  author    = {Li, Zewen and Liu, Fan and Yang, Wenjie and Peng, Shouheng and Zhou, Jun},
  journal   = {IEEE Transactions on Neural Networks and Learning Systems},
  year      = {2021},
  publisher = {IEEE}
}

@article{liu_2020,
  title   = {Computer vision for perception and localization},
  doi     = {10.1002/9781119570516.ch6},
  journal = {Engineering Autonomous Vehicles and Robots},
  author  = {Liu, Shaoshan},
  year    = {2020},
  pages   = {77-96}
}

@article{masters2018revisiting,
  title   = {Revisiting small batch training for deep neural networks},
  author  = {Masters, Dominic and Luschi, Carlo},
  journal = {arXiv preprint arXiv:1804.07612},
  year    = {2018}
}

@article{o2015introduction,
  title   = {An introduction to convolutional neural networks},
  author  = {O'Shea, Keiron and Nash, Ryan},
  journal = {arXiv preprint arXiv:1511.08458},
  year    = {2015}
}

@misc{overview_cv_task,
  title   = {CS231N: Deep Learning for Computer Vision},
  url     = {http://cs231n.stanford.edu/index.html},
  journal = {Stanford University CS231n: Deep Learning for Computer Vision},
  author  = {Li, Fei-Fei and Wu, Jiajun and Gao, Ruohan}
}

@misc{rcnn_vari_flow_chart,
  title     = {What do we learn from region based object detectors (faster R-CNN, R-FCN, FPN)?},
  url       = {https://jonathan-hui.medium.com/what-do-we-learn-from-region-based-object-detectors-faster-r-cnn-r-fcn-fpn-7e354377a7c9},
  journal   = {Medium},
  publisher = {Medium},
  author    = {Hui, Jonathan},
  year      = {2019},
  month     = {Feb}
}

@misc{rcnn_vs_faster_custom_fig,
  title   = {RCNN, fast RCNN, and faster RCNN algorithms for object detection explained},
  url     = {http://www.sefidian.com/2020/01/13/rcnn-fast-rcnn-and-faster-rcnn-for-object-detection-explained/},
  journal = {Amir Masoud Sefidian},
  year    = {2022},
  month   = {Jun}
} 

@misc{relu_optimization_2020,
  doi       = {10.48550/ARXIV.2006.06878},
  url       = {https://arxiv.org/abs/2006.06878},
  author    = {Dukler, Yonatan and Gu, Quanquan and Montúfar, Guido},
  keywords  = {Machine Learning (cs.LG), Optimization and Control (math.OC), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
  title     = {Optimization Theory for ReLU Neural Networks Trained with Normalization Layers},
  publisher = {arXiv},
  year      = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@inproceedings{resnet_2016,
  title     = {Deep residual learning for image recognition},
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {770--778},
  year      = {2016}
}

@misc{roi_pooling_problem,
  title   = {Understanding region of interest (roi pooling)},
  url     = {https://erdem.pl/2020/02/understanding-region-of-interest-ro-i-pooling},
  journal = {Understanding Region of Interest (RoI Pooling) - Blog by Kemal Erdem}
}

@article{selective_search_2013,
  title   = {Selective search for object recognition},
  volume  = {104},
  doi     = {10.1007/s11263-013-0620-5},
  number  = {2},
  journal = {International Journal of Computer Vision},
  author  = {Uijlings, J. R. and van de Sande, K. E. and Gevers, T. and Smeulders, A. W.},
  year    = {2013},
  pages   = {154-171},
  annote  = {This paper proposes a region proposal algorithm named selective search. In the object detection task, the algorithm must be able to detect the location of the object at different scales. These objects' location is called the region of interest. Selective search is an algorithm that proposes potential regions of interest in an image. It is an efficient method for generating a large number of possible regions from an image, which can then be used as input for object recognition systems. The algorithm works by considering different segmentations of the image and then assigning a score to each one based on the similarity of its pixels, color, texture, and size. Some segmentations can then be merged if they have a high similarity score with each other. In addition to providing multiple proposals per image, selective search also benefits from being computationally efficient: compared to some other algorithms, it requires significantly fewer operations per proposal compared to those generated by slower methods such as sliding window approaches. Furthermore, since this approach does not require pre-training or manually labeling data, it can be quickly adapted to solve a wide range of problems with minimal effort on the part of the user.}
} 

@incollection{spatial_pyramid_pooling_2014,
  doi       = {10.1007/978-3-319-10578-9_23},
  url       = {https://doi.org/10.1007%2F978-3-319-10578-9_23},
  year      = 2014,
  publisher = {Springer International Publishing},
  pages     = {346--361},
  author    = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  title     = {Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition},
  booktitle = {Computer Vision {\textendash} {ECCV} 2014}
}

@book{taylor2017neural,
  title     = {Neural Networks: A visual introduction for beginners},
  author    = {Taylor, Michael},
  year      = {2017},
  publisher = {Blue Windmill Media}
}

@article{transposed_convolution_layer_2016,
  title   = {Generating images with recurrent adversarial networks},
  author  = {Im, Daniel Jiwoong and Kim, Chris Dongjoo and Jiang, Hui and Memisevic, Roland},
  journal = {arXiv preprint arXiv:1602.05110},
  year    = {2016}
}

@misc{vgg16_2014,
  doi       = {10.48550/ARXIV.1409.1556},
  url       = {https://arxiv.org/abs/1409.1556},
  author    = {Simonyan, Karen and Zisserman, Andrew},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  publisher = {arXiv},
  year      = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{vgg16_architect_2014,
  author  = {Sugata, T and Yang, C},
  year    = {2017},
  month   = {11},
  pages   = {012004},
  title   = {Leaf App: Leaf recognition with deep convolutional neural networks},
  volume  = {273},
  journal = {IOP Conference Series: Materials Science and Engineering},
  doi     = {10.1088/1757-899X/273/1/012004}
}

@article{wang2019development,
  title     = {Development of convolutional neural network and its application in image classification: a survey},
  author    = {Wang, Wei and Yang, Yujing and Wang, Xin and Wang, Weizheng and Li, Ji},
  journal   = {Optical Engineering},
  volume    = {58},
  number    = {4},
  pages     = {040901},
  year      = {2019},
  publisher = {International Society for Optics and Photonics},
  annote    = {This paper talks about the development history of the Convolutional Neural Network (CNN) and analyzes the architecture layer-by-layer of a CNN model called LeNet-5 in 1998. The paper states a high-level idea of each advancement model in the development process. The paper also quickly talks about the underline algorithm at each layer. For that reason, this paper will act as a high-level guide to the field.}
} 

@article{wang2022review,
  title     = {A Review of Vehicle Detection Techniques for Intelligent Vehicles},
  author    = {Wang, Zhangu and Zhan, Jun and Duan, Chunguang and Guan, Xin and Lu, Pingping and Yang, Kai},
  journal   = {IEEE Transactions on Neural Networks and Learning Systems},
  year      = {2022},
  publisher = {IEEE},
  annote    = {The paper is an overview of the intelligent vehicle system. The system consists of environment interpretation, behavioral decision-making, and motion control. The environment interpretation step is an application of the Convolution Neural Network and the goal of this study. The paper suggested a simplified idea of R-CNN. The idea is to use prior knowledge to quickly identify the region of interest (RoI) and then apply CNN on each RoI to detect and classify the object. The paper also quickly compare the performance of different object detection model.}
}

@inproceedings{zeiler2014visualizing,
  title        = {Visualizing and understanding convolutional networks},
  author       = {Zeiler, Matthew D and Fergus, Rob},
  booktitle    = {European conference on computer vision},
  pages        = {818--833},
  year         = {2014},
  organization = {Springer},
  annote       = {This paper proposes a way to visualize the feature activation function at any layer of any large Convolutional Neural Network (CNN). The proposed technique used a multi-layered Deconvolutional Network (deconvnet) to show which pixel on the original image is affected by the activation function of that layer. The activation function can be any of the unpooling,  rectification, or filtering operations. The technique proposed also can be used to debug problems in a complex CNN model.}
} 