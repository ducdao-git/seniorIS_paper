%% This BibTeX bibliography file was created using BibDesk.
%% http://www.cs.ucsd.edu/~mmccrack/bibdesk.html
%% Created for Jon Breitenbucher at 2005-09-15 16:48:40 -0400 
%% Saved with string encoding UTF-8 

@inbook{2d_svm_Tzotsos,
  author    = {Tzotsos, A.
               and Argialas, D.},
  editor    = {Blaschke, Thomas
               and Lang, Stefan
               and Hay, Geoffrey J.},
  title     = {Support Vector Machine Classification for Object-Based Image Analysis},
  booktitle = {Object-Based Image Analysis: Spatial Concepts for Knowledge-Driven Remote Sensing Applications},
  year      = {2008},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {663--677},
  abstract  = {The Support Vector Machine is a theoretically superior machine learning methodology with great results in pattern recognition. Especially for supervised classification of high-dimensional datasets and has been found competitive with the best machine learning algorithms. In the past, SVMs were tested and evaluated only as pixel-based image classifiers. During recent years, advances in Remote Sensing occurred in the field of Object-Based Image Analysis (OBIA) with combination of low level and high level computer vision techniques. Moving from pixel-based techniques towards object-based representation, the dimensions of remote sensing imagery feature space increases significantly. This results to increased complexity of the classification process, and causes problems to traditional classification schemes. The objective of this study was to evaluate SVMs for their effectiveness and prospects for object-based image analysis as a modern computational intelligence method. Here, an SVM approach for multi-class classification was followed, based on primitive image objects provided by a multi-resolution segmentation algorithm. Then, a feature selection step took place in order to provide the features for classification which involved spectral, texture and shape information. After the feature selection step, a module that integrated an SVM classifier and the segmentation algorithm was developed in C++. For training the SVM, sample image objects derived from the segmentation procedure were used. The proposed classification procedure followed, resulting in the final object classification. The classification results were compared to the Nearest Neighbor object-based classifier results, and were found satisfactory. The SVM methodology seems very promising for Object Based Image Analysis and future work will focus on integrating SVM classifiers with rule-based classifiers.},
  isbn      = {978-3-540-77058-9},
  doi       = {10.1007/978-3-540-77058-9_36},
  url       = {https://doi.org/10.1007/978-3-540-77058-9_36}
}

@misc{ahsan_2020,
  title     = {Convolutional neural network and regularization techniques with TensorFlow and keras},
  url       = {https://medium.com/intelligentmachines/convolutional-neural-network-and-regularization-techniques-with-tensorflow-and-keras-5a09e6e65dc7},
  journal   = {Medium},
  publisher = {intelligentmachines},
  author    = {Ahsan, Ahmad Omar},
  year      = {2020},
  month     = {Jun}
}

@article{AlexNet_2017,
  title     = {Imagenet classification with deep convolutional neural networks},
  author    = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal   = {Communications of the ACM},
  volume    = {60},
  number    = {6},
  pages     = {84--90},
  year      = {2017},
  publisher = {AcM New York, NY, USA}
}

@misc{analytics_vidhya_2021,
  title   = {Building resnet-34 model using Pytorch - A Guide for Beginners},
  url     = {https://www.analyticsvidhya.com/blog/2021/09/building-resnet-34-model-using-pytorch-a-guide-for-beginners/},
  author  = {Siddharth M},
  journal = {Analytics Vidhya},
  year    = {2021},
  month   = {Sep}
}

@article{dropout_2014,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The journal of machine learning research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@inproceedings{FPN_2017,
  title={Feature pyramid networks for object detection},
  author={Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2117--2125},
  year={2017}
}

@inproceedings{googlenet_2015,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1--9},
  year={2015}
}

@article{yolov3_2018,
  title={Yolov3: An incremental improvement},
  author={Redmon, Joseph and Farhadi, Ali},
  journal={arXiv preprint arXiv:1804.02767},
  year={2018}
}

@inproceedings{yolo9000_2017,
  title={YOLO9000: better, faster, stronger},
  author={Redmon, Joseph and Farhadi, Ali},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7263--7271},
  year={2017}
}

@inproceedings{understand_cnn_vs_yolo,
  title={Understanding of object detection based on CNN family and YOLO},
  author={Du, Juan},
  booktitle={Journal of Physics: Conference Series},
  volume={1004},
  pages={012029},
  year={2018},
  organization={IOP Publishing}
}

@incollection{bengio2012practical,
  title     = {Practical recommendations for gradient-based training of deep architectures},
  author    = {Bengio, Yoshua},
  booktitle = {Neural networks: Tricks of the trade},
  pages     = {437--478},
  year      = {2012},
  publisher = {Springer}
}

@article{ImageNet_dataset,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  volume={115},
  pages={211--252},
  year={2015},
  publisher={Springer}
}

@inproceedings{coco_2014,
  title        = {Microsoft coco: Common objects in context},
  author       = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle    = {Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages        = {740--755},
  year         = {2014},
  organization = {Springer}
}

@article{confusion_matrix_2017,
  title     = {A Bayesian interpretation of the confusion matrix},
  author    = {Caelen, Olivier},
  journal   = {Annals of Mathematics and Artificial Intelligence},
  volume    = {81},
  number    = {3-4},
  pages     = {429--450},
  year      = {2017},
  publisher = {Springer}
}

@inproceedings{deconv_rcnn_2018,
  title        = {Deconv R-CNN for small object detection on remote sensing images},
  author       = {Zhang, Wei and Wang, Shihao and Thachan, Sophanyouly and Chen, Jingzhou and Qian, Yuntao},
  booktitle    = {IGARSS 2018-2018 IEEE International Geoscience and Remote Sensing Symposium},
  pages        = {2483--2486},
  year         = {2018},
  organization = {IEEE}
}

@book{diff_detection_segmentation_task_fig,
  title        = {Robotic Manipulation},
  subtitle     = {Perception, Planning, and Control},
  howpublished = {Course Notes for MIT 6.4210},
  author       = {Tedrake, Russ},
  year         = 2022,
  url          = {http://manipulation.mit.edu}
}

@inproceedings{fast_rcnn_og,
  title     = {Fast r-cnn},
  author    = {Girshick, Ross},
  booktitle = {Proceedings of the IEEE international conference on computer vision},
  pages     = {1440--1448},
  year      = {2015}
}

@article{faster_rcnn_2015,
  title   = {Faster r-cnn: Towards real-time object detection with region proposal networks},
  author  = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal = {Advances in neural information processing systems},
  volume  = {28},
  year    = {2015}
}

@article{faster_rcnn_architecture_fig,
  author  = {Deng, Zhipeng and Sun, Hao and Zhou, Shilin and Zhao, Juanping and Lei, Lin and Zou, Huanxin},
  year    = {2018},
  month   = {05},
  pages   = {},
  title   = {Multi-scale object detection in remote sensing imagery with convolutional neural networks},
  volume  = {145},
  journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
  doi     = {10.1016/j.isprsjprs.2018.04.003}
} 

@article{fcn_archite_2018,
  author  = {Piramanayagam, Sankaranarayanan and Saber, Eli and Schwartzkopf, Wade and Koehler, Frederick},
  year    = {2018},
  month   = {09},
  pages   = {1429},
  title   = {Supervised Classification of Multisensor Remotely Sensed Images Using a Deep Learning Framework},
  volume  = {10},
  journal = {Remote Sensing},
  doi     = {10.3390/rs10091429}
}

@article{felzenszwalb_huttenlocher_2004,
  title   = {Efficient graph-based image segmentation},
  volume  = {59},
  doi     = {10.1023/b:visi.0000022288.19776.77},
  number  = {2},
  journal = {International Journal of Computer Vision},
  author  = {Felzenszwalb, Pedro F. and Huttenlocher, Daniel P.},
  year    = {2004},
  pages   = {167-181}
}

@article{fscore_2017,
  title     = {Tanks and temples: Benchmarking large-scale scene reconstruction},
  author    = {Knapitsch, Arno and Park, Jaesik and Zhou, Qian-Yi and Koltun, Vladlen},
  journal   = {ACM Transactions on Graphics (ToG)},
  volume    = {36},
  number    = {4},
  pages     = {1--13},
  year      = {2017},
  publisher = {ACM New York, NY, USA}
}

@inproceedings{generalized_iou,
  title     = {Generalized intersection over union: A metric and a loss for bounding box regression},
  author    = {Rezatofighi, Hamid and Tsoi, Nathan and Gwak, JunYoung and Sadeghian, Amir and Reid, Ian and Savarese, Silvio},
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages     = {658--666},
  year      = {2019}
}

@article{Girshick_R_CNN_2013,
  author     = {Ross B. Girshick and Jeff Donahue and Trevor Darrell and Jitendra Malik},
  title      = {Rich feature hierarchies for accurate object detection and semantic segmentation},
  journal    = {CoRR},
  volume     = {abs/1311.2524},
  year       = {2013},
  url        = {http://arxiv.org/abs/1311.2524},
  eprinttype = {arXiv},
  eprint     = {1311.2524},
  timestamp  = {Mon, 13 Aug 2018 16:48:09 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/GirshickDDM13.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{grigorescu_trasnea_cocias_macesanu_2020,
  title   = {A survey of Deep Learning techniques for autonomous driving},
  author  = {Grigorescu, Sorin and Trasnea, Bogdan and Cocias, Tiberiu and Macesanu, Gigel},
  volume  = {37},
  doi     = {10.1002/rob.21918},
  number  = {3},
  journal = {Journal of Field Robotics},
  year    = {2020},
  pages   = {362-386}
}


@inproceedings{He_2015_ICCV,
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  title     = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  month     = {December},
  year      = {2015}
}

@inproceedings{huang2017densely,
  title     = {Densely connected convolutional networks},
  author    = {Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {4700--4708},
  year      = {2017}
}

@article{instance_segementation_metric_2022,
  title    = {A review on 2D instance segmentation based on deep neural networks},
  journal  = {Image and Vision Computing},
  volume   = {120},
  pages    = {104401},
  year     = {2022},
  issn     = {0262-8856},
  doi      = {https://doi.org/10.1016/j.imavis.2022.104401},
  url      = {https://www.sciencedirect.com/science/article/pii/S0262885622000300},
  author   = {Wenchao Gu and Shuang Bai and Lingxing Kong},
  keywords = {Instance segmentation, Deep neural networks, Computer vision, Review}
}

@incollection{lecun2012efficient,
  title     = {Efficient backprop},
  author    = {LeCun, Yann A and Bottou, Leon and Orr, Genevieve B and Muller, Klaus-Robert},
  booktitle = {Neural networks: Tricks of the trade},
  pages     = {9-48},
  year      = {2012},
  publisher = {Springer},
  annote    = {The paper proposes a Convolutional Neural Network (CNN) model called DenseNet. The idea of this model is that it connects each layer directly to every other layer in the network. This model inspires by the fact that CNN needs shorter paths from the input layer to the output layer. This need is due to the problem of input and gradient information lost as it travels through a deep network. Since all layers are directly connected, this model preserved the state after each layer and the original input information. All information is available until the final classifier, thus making this network data lost proof.}
}

@article{leaky_relu,
  title={Empirical evaluation of rectified activations in convolutional network},
  author={Xu, Bing and Wang, Naiyan and Chen, Tianqi and Li, Mu},
  journal={arXiv preprint arXiv:1505.00853},
  year={2015}
}

@inproceedings{dying_relu,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1026--1034},
  year={2015}
}

@article{cnn_feature_extraction,
  title={A survey of convolutional neural networks: analysis, applications, and prospects},
  author={Li, Zewen and Liu, Fan and Yang, Wenjie and Peng, Shouheng and Zhou, Jun},
  journal={IEEE transactions on neural networks and learning systems},
  year={2021},
  publisher={IEEE}
}

@book{goodfellow_book,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT press}
}

@article{lecun2015deep,
  title     = {Deep learning},
  author    = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal   = {nature},
  volume    = {521},
  number    = {7553},
  pages     = {436--444},
  year      = {2015},
  publisher = {Nature Publishing Group}
}

@article{yolov4_2020,
  title={Yolov4: Optimal speed and accuracy of object detection},
  author={Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
  journal={arXiv preprint arXiv:2004.10934},
  year={2020}
}

@article{yolov5_review,
  title={A Review of Yolo algorithm developments},
  author={Jiang, Peiyuan and Ergu, Daji and Liu, Fangyao and Cai, Ying and Ma, Bo},
  journal={Procedia Computer Science},
  volume={199},
  pages={1066--1073},
  year={2022},
  publisher={Elsevier}
}

@article{li2021survey,
  title     = {A survey of convolutional neural networks: analysis, applications, and prospects},
  author    = {Li, Zewen and Liu, Fan and Yang, Wenjie and Peng, Shouheng and Zhou, Jun},
  journal   = {IEEE Transactions on Neural Networks and Learning Systems},
  year      = {2021},
  publisher = {IEEE}
} 

@article{liu_2020,
  title   = {Computer vision for perception and localization},
  doi     = {10.1002/9781119570516.ch6},
  journal = {Engineering Autonomous Vehicles and Robots},
  author  = {Liu, Shaoshan},
  year    = {2020},
  pages   = {77-96}
}

@inproceedings{mask_rcnn_2017,
  title     = {Mask r-cnn},
  author    = {He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle = {Proceedings of the IEEE international conference on computer vision},
  pages     = {2961--2969},
  year      = {2017}
} 

@article{masters2018revisiting,
  title   = {Revisiting small batch training for deep neural networks},
  author  = {Masters, Dominic and Luschi, Carlo},
  journal = {arXiv preprint arXiv:1804.07612},
  year    = {2018}
} 

@inproceedings{metrics_survey_2020,
  title        = {A survey on performance metrics for object-detection algorithms},
  author       = {Padilla, Rafael and Netto, Sergio L and Da Silva, Eduardo AB},
  booktitle    = {2020 international conference on systems, signals and image processing (IWSSIP)},
  pages        = {237--242},
  year         = {2020},
  organization = {IEEE}
} 

@article{n_point_interpolation_ap,
  title     = {An enhanced N-point interpolation method to eliminate average precision distortion},
  author    = {Zhang, Haodi and Rogozan, Alexandrina and Bensrhair, Abdelaziz},
  journal   = {Pattern Recognition Letters},
  volume    = {158},
  pages     = {111--116},
  year      = {2022},
  publisher = {Elsevier}
}

@misc{nuimages_dataset,
  title   = {nuImages dataset},
  url     = {https://www.nuscenes.org/nuimages},
  journal = {Nuscenes.org},
  author  = {Motional}
}

@article{svm_sift,
  title={Distinctive image features from scale-invariant keypoints},
  author={Lowe, David G},
  journal={International journal of computer vision},
  volume={60},
  pages={91--110},
  year={2004},
  publisher={Springer}
}

@inproceedings{svm_hog,
  title={Histograms of oriented gradients for human detection},
  author={Dalal, Navneet and Triggs, Bill},
  booktitle={2005 IEEE computer society conference on computer vision and pattern recognition (CVPR'05)},
  volume={1},
  pages={886--893},
  year={2005},
  organization={Ieee}
}

@article{o2015introduction,
  title   = {An introduction to convolutional neural networks},
  author  = {O'Shea, Keiron and Nash, Ryan},
  journal = {arXiv preprint arXiv:1511.08458},
  year    = {2015}
}

@misc{overview_cv_task,
  title   = {CS231N: Deep Learning for Computer Vision},
  url     = {http://cs231n.stanford.edu/index.html},
  journal = {Stanford University CS231n: Deep Learning for Computer Vision},
  author  = {Li, Fei-Fei and Wu, Jiajun and Gao, Ruohan}
}

@article{pascal_voc_2015,
  title     = {The pascal visual object classes challenge: A retrospective},
  author    = {Everingham, Mark and Eslami, SM Ali and Van Gool, Luc and Williams, Christopher KI and Winn, John and Zisserman, Andrew},
  journal   = {International journal of computer vision},
  volume    = {111},
  pages     = {98--136},
  year      = {2015},
  publisher = {Springer}
}

@inproceedings{yolov1_2016,
  title={You only look once: Unified, real-time object detection},
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={779--788},
  year={2016}
}

@inproceedings{pdq_metric_2020,
  title     = {Probabilistic object detection: Definition and evaluation},
  author    = {Hall, David and Dayoub, Feras and Skinner, John and Zhang, Haoyang and Miller, Dimity and Corke, Peter and Carneiro, Gustavo and Angelova, Anelia and S{\"u}nderhauf, Niko},
  booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages     = {1031--1040},
  year      = {2020}
}

@misc{skm_multilabel_confusion_matrix,
  title   = {Sklearn.metrics.multilabel\_confusion\_matrix Function Documentation},
  url     = {https://scikit-learn.org/stable/modules/generated/sklearn.metrics.multilabel_confusion_matrix.html},
  journal = {scikit}
} 

@misc{python3_docs,
  title   = {Python3 Official Documents Programming FAQ},
  url     = {https://docs.python.org/3/faq/programming.html#how-do-i-write-a-function-with-output-parameters-call-by-reference},
  journal = {Python documentation}
}

@misc{pytorch_yolov5, title={Pytorch}, url={https://pytorch.org/hub/ultralytics_yolov5/}, journal={PyTorch}} 

@misc{pytorch_mrcnn,
  title   = {Pytorch Documentation Maskrcnn\_resnet50\_fpn Method},
  url     = {https://pytorch.org/vision/main/models/generated/torchvision.models.detection.maskrcnn_resnet50_fpn.html#torchvision.models.detection.maskrcnn_resnet50_fpn},
  journal = {maskrcnn_resnet50_fpn - Torchvision main documentation}
} 

@misc{rcnn_vari_flow_chart,
  title     = {What do we learn from region based object detectors (faster R-CNN, R-FCN, FPN)?},
  url       = {https://jonathan-hui.medium.com/what-do-we-learn-from-region-based-object-detectors-faster-r-cnn-r-fcn-fpn-7e354377a7c9},
  journal   = {Medium},
  publisher = {Medium},
  author    = {Hui, Jonathan},
  year      = {2019},
  month     = {Feb}
}


@misc{rcnn_vs_faster_custom_fig,
  title   = {RCNN, fast RCNN, and faster RCNN algorithms for object detection explained},
  url     = {http://www.sefidian.com/2020/01/13/rcnn-fast-rcnn-and-faster-rcnn-for-object-detection-explained/},
  journal = {Amir Masoud Sefidian},
  year    = {2022},
  month   = {Jun}
}

@misc{relu_optimization_2020,
  doi       = {10.48550/ARXIV.2006.06878},
  url       = {https://arxiv.org/abs/2006.06878},
  author    = {Dukler, Yonatan and Gu, Quanquan and Montúfar, Guido},
  keywords  = {Machine Learning (cs.LG), Optimization and Control (math.OC), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
  title     = {Optimization Theory for ReLU Neural Networks Trained with Normalization Layers},
  publisher = {arXiv},
  year      = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{yolov5_github, title={Ultralytics/Yolov5 at blog.roboflow.com}, url={https://github.com/ultralytics/yolov5?ref=blog.roboflow.com}, journal={GitHub}, author={Ultralytics, Ultralytics}} 

@inproceedings{resnet_2016,
  title     = {Deep residual learning for image recognition},
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {770--778},
  year      = {2016}
} 

@misc{roi_pooling_problem,
  title   = {Understanding region of interest (roi pooling)},
  url     = {https://erdem.pl/2020/02/understanding-region-of-interest-ro-i-pooling},
  journal = {Understanding Region of Interest (RoI Pooling) - Blog by Kemal Erdem}
}

@article{selective_search_2013,
  title   = {Selective search for object recognition},
  volume  = {104},
  doi     = {10.1007/s11263-013-0620-5},
  number  = {2},
  journal = {International Journal of Computer Vision},
  author  = {Uijlings, J. R. and van de Sande, K. E. and Gevers, T. and Smeulders, A. W.},
  year    = {2013},
  pages   = {154-171},
  % annote  = {This paper proposes a region proposal algorithm named selective search. In the object detection task, the algorithm must be able to detect the location of the object at different scales. These objects' location is called the region of interest. Selective search is an algorithm that proposes potential regions of interest in an image. It is an efficient method for generating a large number of possible regions from an image, which can then be used as input for object recognition systems. The algorithm works by considering different segmentations of the image and then assigning a score to each one based on the similarity of its pixels, color, texture, and size. Some segmentations can then be merged if they have a high similarity score with each other. In addition to providing multiple proposals per image, selective search also benefits from being computationally efficient: compared to some other algorithms, it requires significantly fewer operations per proposal compared to those generated by slower methods such as sliding window approaches. Furthermore, since this approach does not require pre-training or manually labeling data, it can be quickly adapted to solve a wide range of problems with minimal effort on the part of the user.}
}

@book{traditional_machine_learning,
  title={Pattern recognition and machine learning},
  author={Bishop, Christopher M and Nasrabadi, Nasser M},
  volume={4},
  number={4},
  year={2006},
  publisher={Springer}
}

@article{ai_data_driven,
  title={Machine learning: Trends, perspectives, and prospects},
  author={Jordan, Michael I and Mitchell, Tom M},
  journal={Science},
  volume={349},
  number={6245},
  pages={255--260},
  year={2015},
  publisher={American Association for the Advancement of Science}
}

@misc{autonomous_vehicle_market, title={Autonomous vehicle market size, share, value, report, growth}, url={https://www.alliedmarket-research.com/autonomous-vehicle-market}, journal={Allied Market Research}} 

@misc{tesla_2017_promise, title={Elon Musk: Fully autonomous tesla will drive across the country by the end of 2017}, url={https://www.businessinsider.com/elon-musk-autonomous-tesla-drive-across-country-by-end-of-2017-2016-10}, journal={Business Insider}, publisher={Business Insider}, author={Thompson, Cadie}} 

@misc{tesla_crash1, title={Driver to stand trial in Tesla Autopilot crash which killed two in Gardena}, url={https://www.cbsnews.com/losangeles/news/driver-to-stand-trial-in-tesla-autopilot-crash-which-killed-two-in-gardena/}, journal={CBS News}, publisher={CBS Interactive}, year={2022}, month={May}} 

@misc{tesla_crash2, title={Tesla Autopilot's safety questioned after latest fatal motorcycle crash | CNN business}, url={https://www.cnn.com/2022/10/17/business/tesla-motorcycle-crashes-autopilot/index.html}, journal={CNN}, publisher={Cable News Network}, author={McFarland, Matt}, year={2022}, month={Oct}}

@misc{tesla_software_v7, title={autopilot improvements autosteer: new safety restriction - tesla, inc..,}, url={https://www.tesla.com/sites/default/files/pdfs/release_notes/tesla_model_s_software_7_1.pdf}} 

@inproceedings{smoth_ap_metric_2020,
  title        = {Smooth-ap: Smoothing the path towards large-scale image retrieval},
  author       = {Brown, Andrew and Xie, Weidi and Kalogeiton, Vicky and Zisserman, Andrew},
  booktitle    = {Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part IX 16},
  pages        = {677--694},
  year         = {2020},
  organization = {Springer}
}

@incollection{spatial_pyramid_pooling_2014,
  doi       = {10.1007/978-3-319-10578-9_23},
  url       = {https://doi.org/10.1007%2F978-3-319-10578-9_23},
  year      = 2014,
  publisher = {Springer International Publishing},
  pages     = {346--361},
  author    = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  title     = {Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition},
  booktitle = {Computer Vision {\textendash} {ECCV} 2014}
}

@book{szeliski_cv_book,
  title     = {Computer vision: algorithms and applications},
  author    = {Szeliski, Richard},
  year      = {2022},
  publisher = {Springer Nature}
}

@book{taylor2017neural,
  title     = {Neural Networks: A visual introduction for beginners},
  author    = {Taylor, Michael},
  year      = {2017},
  publisher = {Blue Windmill Media}
} 

@article{transposed_convolution_layer_2016,
  title   = {Generating images with recurrent adversarial networks},
  author  = {Im, Daniel Jiwoong and Kim, Chris Dongjoo and Jiang, Hui and Memisevic, Roland},
  journal = {arXiv preprint arXiv:1602.05110},
  year    = {2016}
}

@misc{vgg16_2014,
  doi       = {10.48550/ARXIV.1409.1556},
  url       = {https://arxiv.org/abs/1409.1556},
  author    = {Simonyan, Karen and Zisserman, Andrew},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  publisher = {arXiv},
  year      = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
} 

@article{vgg16_architect_2014,
  author  = {Sugata, T and Yang, C},
  year    = {2017},
  month   = {11},
  pages   = {012004},
  title   = {Leaf App: Leaf recognition with deep convolutional neural networks},
  volume  = {273},
  journal = {IOP Conference Series: Materials Science and Engineering},
  doi     = {10.1088/1757-899X/273/1/012004}
}

@article{wang2019development,
  title     = {Development of convolutional neural network and its application in image classification: a survey},
  author    = {Wang, Wei and Yang, Yujing and Wang, Xin and Wang, Weizheng and Li, Ji},
  journal   = {Optical Engineering},
  volume    = {58},
  number    = {4},
  pages     = {040901},
  year      = {2019},
  publisher = {International Society for Optics and Photonics},
  annote    = {This paper talks about the development history of the Convolutional Neural Network (CNN) and analyzes the architecture layer-by-layer of a CNN model called LeNet-5 in 1998. The paper states a high-level idea of each advancement model in the development process. The paper also quickly talks about the underline algorithm at each layer. For that reason, this paper will act as a high-level guide to the field.}
} 

@article{wang2022review,
  title     = {A Review of Vehicle Detection Techniques for Intelligent Vehicles},
  author    = {Wang, Zhangu and Zhan, Jun and Duan, Chunguang and Guan, Xin and Lu, Pingping and Yang, Kai},
  journal   = {IEEE Transactions on Neural Networks and Learning Systems},
  year      = {2022},
  publisher = {IEEE},
  annote    = {The paper is an overview of the intelligent vehicle system. The system consists of environment interpretation, behavioral decision-making, and motion control. The environment interpretation step is an application of the Convolution Neural Network and the goal of this study. The paper suggested a simplified idea of R-CNN. The idea is to use prior knowledge to quickly identify the region of interest (RoI) and then apply CNN on each RoI to detect and classify the object. The paper also quickly compare the performance of different object detection model.}
} 

@inproceedings{zeiler2014visualizing,
  title        = {Visualizing and understanding convolutional networks},
  author       = {Zeiler, Matthew D and Fergus, Rob},
  booktitle    = {European conference on computer vision},
  pages        = {818--833},
  year         = {2014},
  organization = {Springer},
  annote       = {This paper proposes a way to visualize the feature activation function at any layer of any large Convolutional Neural Network (CNN). The proposed technique used a multi-layered Deconvolutional Network (deconvnet) to show which pixel on the original image is affected by the activation function of that layer. The activation function can be any of the unpooling,  rectification, or filtering operations. The technique proposed also can be used to debug problems in a complex CNN model.}
} 